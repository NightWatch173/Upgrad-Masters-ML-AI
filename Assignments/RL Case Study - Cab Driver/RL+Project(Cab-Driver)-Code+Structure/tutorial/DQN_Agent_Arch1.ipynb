{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cab-Driver Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import deque\n",
    "import collections\n",
    "import pickle\n",
    "\n",
    "# # for building DQN model\n",
    "# from keras import layers\n",
    "# from keras import Sequential\n",
    "# from keras.layers import Dense, Activation, Flatten\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "# for plotting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the environment\n",
    "# from Env import CabDriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Time Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the time matrix provided\n",
    "Time_matrix = np.load(\"TM.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 24, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time_matrix[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking the state-action pairs for checking convergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time_matrix[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time_matrix[2][1][12][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 24, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for _ in range(100):\n",
    "#     print(np.random.poisson(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to save the Q-dictionary as a pickle file\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Class\n",
    "\n",
    "If you are using this framework, you need to fill the following to complete the following code block:\n",
    "1. State and Action Size\n",
    "2. Hyperparameters\n",
    "3. Create a neural-network model in function 'build_model()'\n",
    "4. Define epsilon-greedy strategy in function 'get_action()'\n",
    "5. Complete the function 'append_sample()'. This function appends the recent experience tuple <state, action, reward, new-state> to the memory\n",
    "6. Complete the 'train_model()' function with following logic:\n",
    "   - If the memory size is greater than mini-batch size, you randomly sample experiences from memory as per the mini-batch size and do the following:\n",
    "      - Initialise your input and output batch for training the model\n",
    "      - Calculate the target Q value for each sample: reward + gamma*max(Q(s'a,))\n",
    "      - Get Q(s', a) values from the last trained model\n",
    "      - Update the input batch as your encoded state and output batch as your Q-values\n",
    "      - Then fit your DQN model using the updated input and output batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        # Define size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # Write here: Specify you hyper parameters for the DQN\n",
    "        self.discount_factor = \n",
    "        self.learning_rate =  0.001 \n",
    "        self.epsilon_max = 1.0\n",
    "        self.epsilon_decay = \n",
    "        self.epsilon_min = 0.00000001\n",
    "        \n",
    "        self.batch_size = 256\n",
    "        # create replay memory using deque\n",
    "        self.memory = deque(maxlen=2000)\n",
    "\n",
    "        # create main model and target model\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    \n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        # Write your code here: Add layers to your neural nets\n",
    "        model.add(Dense(50,activation='relu',input_dim= self.state_size))\n",
    "        \n",
    "        model.compile(loss='mse',optimizer=Adam(lr=self.learning_rate))\n",
    "        model.summary\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "    def get_action(self, state,episodes):\n",
    "        # Write your code here:\n",
    "        # get action from model using epsilon-greedy policy\n",
    "        # Decay in Îµ after we generate each sample from the environment       \n",
    "        if z>e:\n",
    "            # model.predict(state)\n",
    "            # best action - from possible action \n",
    "        else:\n",
    "            #randomly select the actions - from possible action\n",
    "\n",
    "\n",
    "    def append_sample(self, state, action, reward, next_state):\n",
    "        self.memory.append((state, action, reward, next_state))\n",
    "    # Write your code here:\n",
    "    # save sample <s,a,r,s'> to the replay memory\n",
    "    \n",
    "    \n",
    "    \n",
    "    # pick samples randomly from replay memory (with batch_size) and train the network\n",
    "    def train_model(self):\n",
    "        if len(self.memory) > self.batch_size:\n",
    "            # Sample batch from the memory\n",
    "            mini_batch = random.sample(self.memory, self.batch_size)\n",
    "            [(s,a,r,s'),(s,a,r,s') .... ]\n",
    "            update_output = np.zeros((self.batch_size,self.state_size))# write here\n",
    "            update_input = np.zeros((self.batch_size,self.state_size))# write here\n",
    "            actions, rewards = [], []\n",
    "            \n",
    "            for i in range(self.batch_size):\n",
    "                state, action, reward, next_state = mini_batch[i]\n",
    "                \n",
    "                actions.append(action)\n",
    "                rewards.append(reward)\n",
    "                \n",
    "                # Write your code from here\n",
    "                # 1.  Update your 'update_output' and 'update_input' batch\n",
    "                update_input[i] = env.state_encode_arch(state)\n",
    "                update_output[i] = env.state_encode_arch(next_state)\n",
    "\n",
    "            q_vals = model.predit(update_output) ## (batchsize,len(action_space))\n",
    "            target = model.predit(update_input)\n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                target[i][actions[i]] = rewards[i]+discount_factor*max(q_vals[i])\n",
    "\n",
    "            self.model.fit(update_input, target)\n",
    "                \n",
    "        # 4. Fit your model and track the loss values\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Episodes = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DQNagent(...)\n",
    "for episode in range(Episodes):\n",
    "\n",
    "    \n",
    "    # Write code here\n",
    "    # Call the environment\n",
    "    # Call all the initialised variables of the environment\n",
    "    #Call the DQN agent\n",
    "    count=0\n",
    "    while !terminal_state:\n",
    "        count+=1\n",
    "        action = agent.get_action(state,episode)\n",
    "        reward = env.reward_func(state,action,time_matrix)\n",
    "        next_state,terminal_state = env.next_state_func(state,action,time_matrix)\n",
    "        #Append the experience to the memory\n",
    "        # Write your code here\n",
    "        # 1. Pick epsilon-greedy action from possible actions for the current state\n",
    "        # 2. Evaluate your reward and next state\n",
    "        # 3. Append the experience to the memory\n",
    "        if count%20 == 0:\n",
    "            # 4. Train the model by calling function agent.train_model\n",
    "            # 5. Keep a track of rewards, Q-values, loss\n",
    "            agent.train_model()\n",
    "    if episode% ==:\n",
    "        agent.save('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epsilon-decay sample function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Try building a similar epsilon-decay function for your model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0,100000)\n",
    "epsilon = []\n",
    "for i in range(0,100000):\n",
    "    epsilon.append(0 + (1 - 0) * np.exp(-0.00005*i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time, epsilon)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z:0-1\n",
    "e:0\n",
    "e>z"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
